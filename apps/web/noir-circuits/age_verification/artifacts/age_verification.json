{
  "noir_version": "1.0.0-beta.16+2d46fca7203545cbbfb31a0d0328de6c10a8db95",
  "hash": "11142634866140154615",
  "abi": {
    "parameters": [
      {
        "name": "birth_year",
        "type": { "kind": "field" },
        "visibility": "private"
      },
      {
        "name": "document_hash",
        "type": { "kind": "field" },
        "visibility": "private"
      },
      {
        "name": "current_year",
        "type": { "kind": "field" },
        "visibility": "public"
      },
      {
        "name": "min_age",
        "type": { "kind": "field" },
        "visibility": "public"
      },
      { "name": "nonce", "type": { "kind": "field" }, "visibility": "public" },
      {
        "name": "claim_hash",
        "type": { "kind": "field" },
        "visibility": "public"
      }
    ],
    "return_type": {
      "abi_type": { "kind": "boolean" },
      "visibility": "public"
    },
    "error_types": {
      "1998584279744703196": {
        "error_kind": "string",
        "string": "attempt to subtract with overflow"
      },
      "10050030960492158455": {
        "error_kind": "string",
        "string": "Claim hash mismatch"
      },
      "15783691831417874490": {
        "error_kind": "string",
        "string": "Birth year cannot be in the future"
      }
    }
  },
  "bytecode": "H4sIAAAAAAAA/7VYvW4TQRCe9dmJfxLHjs927NjksJtAFURHQ4EiUSE6aFCEyAm5wIBlIihTUwEvQMkTIJB4iPRESC6QgCoNojQ+ZyeerNd3O3vnlU5zvpnZ+ebb3c9nCzgfaWmfPe71uxO7B/NDSOtJu3d4bzC68fHal/v7n4+PHz7avfnr7puvL97dGf39cDbxr5JYzuDWyUJknRSdew1m/Qpi8VqVNkvicpMrP7kKMl83uWeINwPGvIiceewF1pRuIgVjVF1GrHZ40SHTGhTrurRF9DrSBo4fyrOipohjXvwCAMaGLNr7yaKJdTBf4CLYkcfdSBxMG3AZU1g85TnIC7hPw+yAaIm0xG2CBUcpTsGShuCo3BKYb6YyA49tD2XQn+Sw3DLwNiNXKYoSV4qRtzEejzl8bYJ5D3TzYl6SypgCHp/q8KJD5pSxIq2LXmwwcKjK6EJ8ZaRNRiljBcwX0gU78rjKyMFUBTtlDPKSVsYKEwuOWpyCNeArYw3MN1Odgce2hzrwlbEOy1VGV+LiKiOHry0w74FuXsxLUhkd4PGpDi86ZE4ZG9I20YsNBg5VGZsQXxlpk1HK2ADzhWyCHXlcZeRg2gY7ZQzyklbGBhMLjlacgi3gK2MLzDdTm4HHtoc28JWxDctVxqbExVVGDl9XwLwHunkxL0wZuYeO8YNQGL4iiUUOD8xyaV87NJeS4cH8hGkaDMtrPkpddxgYPLAjlXvgKCZOLYdZZwmcTue9CnaHBvOSPDSMb0RhiDvRQ9ORtoteJKMDs689fNaF+AfJlpCog9RhYOiCHdEcpQ/yVxiYOubzXlrAACTdsI78nIFZAyswO5xA7v+1T/Z/j16/pXPvSnvr088HW2f579R3XdrTP6e3T/xv2yqeprSHvYH/ZNg78g96/aH/1B8cvHz1fNjz+8OsjECbJ10w3rxTmF+wy58yoo48uS+oBaVNa/LEgs8pxYbFhr1crml8OOemtBQv9oF/NNLVOPIHw5x8jhxWST0GhwLzXbt87RpUyT3Oi3Uojx7wBu74jManrq2j1EUr+PXFIhy69ca1dMkz5OM/OOqLmuIaAAA=",
  "debug_symbols": "nZVBbsMgEEXvwtoLZhgM9CpVFTkJqSxZTuTalaqody+EgcQLrMqrF5v8J2DGcBdnf1w+D/14uX6Jt/e7OE79MPSfh+F66ub+Ooa3999G5MfDPHkfXomX8ZC6dZMfZ/E2LsPQiO9uWB5/+rp144NzN4VR2Qg/ngOD8NIPPv76bZ5pWY8CtobToKQuAg0rA2wZdBY4eOZplcd6XmnkPEFb8gZXeVXPI1rHAlQSawbaWAG0eQoAVu+Zg4E2z8EoWTO0G3MwRuU5GFddhakbHOU6OG135EFi2QXZVnfB1Q1kIU+BrH6uAdy/d8FJV5oJq7uw1c8KbOlnqvbzloF0qQQZucvgyio02D0GTaUWWrd7DMaU79oC7DE4glILQzsMKMvRgJLUyvARnrpTP63OQyFj7zUCEjBBxTOmERQr2gid0CaYBJvgEkAygYlMxWQVRFc4F6BlGqZlukSUTGAiUzGJyT6MvrByNEzLdIlKMoGJTMUkpmayT0Vf+HqUZbpEkszoC1UnZEZf+BqImJoZfbEtv7up746D57vosoynl6tp/rnlkXx53abryZ+XyceyPcZCIf8A",
  "file_map": {
    "19": {
      "source": "// Exposed only for usage in `std::meta`\npub(crate) mod poseidon2;\n\nuse crate::default::Default;\nuse crate::embedded_curve_ops::{\n    EmbeddedCurvePoint, EmbeddedCurveScalar, multi_scalar_mul, multi_scalar_mul_array_return,\n};\nuse crate::meta::derive_via;\n\n#[foreign(sha256_compression)]\n// docs:start:sha256_compression\npub fn sha256_compression(input: [u32; 16], state: [u32; 8]) -> [u32; 8] {}\n// docs:end:sha256_compression\n\n#[foreign(keccakf1600)]\n// docs:start:keccakf1600\npub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {}\n// docs:end:keccakf1600\n\npub mod keccak {\n    #[deprecated(\"This function has been moved to std::hash::keccakf1600\")]\n    pub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {\n        super::keccakf1600(input)\n    }\n}\n\n#[foreign(blake2s)]\n// docs:start:blake2s\npub fn blake2s<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake2s\n{}\n\n// docs:start:blake3\npub fn blake3<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake3\n{\n    if crate::runtime::is_unconstrained() {\n        // Temporary measure while Barretenberg is main proving system.\n        // Please open an issue if you're working on another proving system and running into problems due to this.\n        crate::static_assert(\n            N <= 1024,\n            \"Barretenberg cannot prove blake3 hashes with inputs larger than 1024 bytes\",\n        );\n    }\n    __blake3(input)\n}\n\n#[foreign(blake3)]\nfn __blake3<let N: u32>(input: [u8; N]) -> [u8; 32] {}\n\n// docs:start:pedersen_commitment\npub fn pedersen_commitment<let N: u32>(input: [Field; N]) -> EmbeddedCurvePoint {\n    // docs:end:pedersen_commitment\n    pedersen_commitment_with_separator(input, 0)\n}\n\n#[inline_always]\npub fn pedersen_commitment_with_separator<let N: u32>(\n    input: [Field; N],\n    separator: u32,\n) -> EmbeddedCurvePoint {\n    let mut points = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N];\n    for i in 0..N {\n        // we use the unsafe version because the multi_scalar_mul will constrain the scalars.\n        points[i] = from_field_unsafe(input[i]);\n    }\n    let generators = derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    multi_scalar_mul(generators, points)\n}\n\n// docs:start:pedersen_hash\npub fn pedersen_hash<let N: u32>(input: [Field; N]) -> Field\n// docs:end:pedersen_hash\n{\n    pedersen_hash_with_separator(input, 0)\n}\n\n#[no_predicates]\npub fn pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    let mut scalars: [EmbeddedCurveScalar; N + 1] = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N + 1];\n    let mut generators: [EmbeddedCurvePoint; N + 1] =\n        [EmbeddedCurvePoint::point_at_infinity(); N + 1];\n    let domain_generators: [EmbeddedCurvePoint; N] =\n        derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n\n    for i in 0..N {\n        scalars[i] = from_field_unsafe(input[i]);\n        generators[i] = domain_generators[i];\n    }\n    scalars[N] = EmbeddedCurveScalar { lo: N as Field, hi: 0 as Field };\n\n    let length_generator: [EmbeddedCurvePoint; 1] =\n        derive_generators(\"pedersen_hash_length\".as_bytes(), 0);\n    generators[N] = length_generator[0];\n    multi_scalar_mul_array_return(generators, scalars, true)[0].x\n}\n\n#[field(bn254)]\n#[inline_always]\npub fn derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {\n    crate::assert_constant(domain_separator_bytes);\n    // TODO(https://github.com/noir-lang/noir/issues/5672): Add back assert_constant on starting_index\n    __derive_generators(domain_separator_bytes, starting_index)\n}\n\n#[builtin(derive_pedersen_generators)]\n#[field(bn254)]\nfn __derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {}\n\n#[field(bn254)]\n// Decompose the input 'bn254 scalar' into two 128 bits limbs.\n// It is called 'unsafe' because it does not assert the limbs are 128 bits\n// Assuming the limbs are 128 bits:\n// Assert the decomposition does not overflow the field size.\nfn from_field_unsafe(scalar: Field) -> EmbeddedCurveScalar {\n    // Safety: xlo and xhi decomposition is checked below\n    let (xlo, xhi) = unsafe { crate::field::bn254::decompose_hint(scalar) };\n    // Check that the decomposition is correct\n    assert_eq(scalar, xlo + crate::field::bn254::TWO_POW_128 * xhi);\n    // Check that the decomposition does not overflow the field size\n    let (a, b) = if xhi == crate::field::bn254::PHI {\n        (xlo, crate::field::bn254::PLO)\n    } else {\n        (xhi, crate::field::bn254::PHI)\n    };\n    crate::field::bn254::assert_lt(a, b);\n\n    EmbeddedCurveScalar { lo: xlo, hi: xhi }\n}\n\npub fn poseidon2_permutation<let N: u32>(input: [Field; N], state_len: u32) -> [Field; N] {\n    assert_eq(input.len(), state_len);\n    poseidon2_permutation_internal(input)\n}\n\n#[foreign(poseidon2_permutation)]\nfn poseidon2_permutation_internal<let N: u32>(input: [Field; N]) -> [Field; N] {}\n\n// Generic hashing support.\n// Partially ported and impacted by rust.\n\n// Hash trait shall be implemented per type.\n#[derive_via(derive_hash)]\npub trait Hash {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher;\n}\n\n// docs:start:derive_hash\ncomptime fn derive_hash(s: TypeDefinition) -> Quoted {\n    let name = quote { $crate::hash::Hash };\n    let signature = quote { fn hash<H>(_self: Self, _state: &mut H) where H: $crate::hash::Hasher };\n    let for_each_field = |name| quote { _self.$name.hash(_state); };\n    crate::meta::make_trait_impl(\n        s,\n        name,\n        signature,\n        for_each_field,\n        quote {},\n        |fields| fields,\n    )\n}\n// docs:end:derive_hash\n\n// Hasher trait shall be implemented by algorithms to provide hash-agnostic means.\n// TODO: consider making the types generic here ([u8], [Field], etc.)\npub trait Hasher {\n    fn finish(self) -> Field;\n\n    fn write(&mut self, input: Field);\n}\n\n// BuildHasher is a factory trait, responsible for production of specific Hasher.\npub trait BuildHasher {\n    type H: Hasher;\n\n    fn build_hasher(self) -> H;\n}\n\npub struct BuildHasherDefault<H>;\n\nimpl<H> BuildHasher for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    type H = H;\n\n    fn build_hasher(_self: Self) -> H {\n        H::default()\n    }\n}\n\nimpl<H> Default for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    fn default() -> Self {\n        BuildHasherDefault {}\n    }\n}\n\nimpl Hash for Field {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self);\n    }\n}\n\nimpl Hash for u1 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u128 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u8 as Field);\n    }\n}\n\nimpl Hash for i16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u16 as Field);\n    }\n}\n\nimpl Hash for i32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u32 as Field);\n    }\n}\n\nimpl Hash for i64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u64 as Field);\n    }\n}\n\nimpl Hash for bool {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for () {\n    fn hash<H>(_self: Self, _state: &mut H)\n    where\n        H: Hasher,\n    {}\n}\n\nimpl<T, let N: u32> Hash for [T; N]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<T> Hash for [T]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.len().hash(state);\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<A, B> Hash for (A, B)\nwhere\n    A: Hash,\n    B: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n    }\n}\n\nimpl<A, B, C> Hash for (A, B, C)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n    }\n}\n\nimpl<A, B, C, D> Hash for (A, B, C, D)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n    }\n}\n\nimpl<A, B, C, D, E> Hash for (A, B, C, D, E)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n    E: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n        self.4.hash(state);\n    }\n}\n\n// Some test vectors for Pedersen hash and Pedersen Commitment.\n// They have been generated using the same functions so the tests are for now useless\n// but they will be useful when we switch to Noir implementation.\n#[test]\nfn assert_pedersen() {\n    assert_eq(\n        pedersen_hash_with_separator([1], 1),\n        0x1b3f4b1a83092a13d8d1a59f7acb62aba15e7002f4440f2275edb99ebbc2305f,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1], 1),\n        EmbeddedCurvePoint {\n            x: 0x054aa86a73cb8a34525e5bbed6e43ba1198e860f5f3950268f71df4591bde402,\n            y: 0x209dcfbf2cfb57f9f6046f44d71ac6faf87254afc7407c04eb621a6287cac126,\n            is_infinite: false,\n        },\n    );\n\n    assert_eq(\n        pedersen_hash_with_separator([1, 2], 2),\n        0x26691c129448e9ace0c66d11f0a16d9014a9e8498ee78f4d69f0083168188255,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2], 2),\n        EmbeddedCurvePoint {\n            x: 0x2e2b3b191e49541fe468ec6877721d445dcaffe41728df0a0eafeb15e87b0753,\n            y: 0x2ff4482400ad3a6228be17a2af33e2bcdf41be04795f9782bd96efe7e24f8778,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3], 3),\n        0x0bc694b7a1f8d10d2d8987d07433f26bd616a2d351bc79a3c540d85b6206dbe4,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3], 3),\n        EmbeddedCurvePoint {\n            x: 0x1fee4e8cf8d2f527caa2684236b07c4b1bad7342c01b0f75e9a877a71827dc85,\n            y: 0x2f9fedb9a090697ab69bf04c8bc15f7385b3e4b68c849c1536e5ae15ff138fd1,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4], 4),\n        0xdae10fb32a8408521803905981a2b300d6a35e40e798743e9322b223a5eddc,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4], 4),\n        EmbeddedCurvePoint {\n            x: 0x07ae3e202811e1fca39c2d81eabe6f79183978e6f12be0d3b8eda095b79bdbc9,\n            y: 0x0afc6f892593db6fbba60f2da558517e279e0ae04f95758587760ba193145014,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5], 5),\n        0xfc375b062c4f4f0150f7100dfb8d9b72a6d28582dd9512390b0497cdad9c22,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5], 5),\n        EmbeddedCurvePoint {\n            x: 0x1754b12bd475a6984a1094b5109eeca9838f4f81ac89c5f0a41dbce53189bb29,\n            y: 0x2da030e3cfcdc7ddad80eaf2599df6692cae0717d4e9f7bfbee8d073d5d278f7,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6], 6),\n        0x1696ed13dc2730062a98ac9d8f9de0661bb98829c7582f699d0273b18c86a572,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6], 6),\n        EmbeddedCurvePoint {\n            x: 0x190f6c0e97ad83e1e28da22a98aae156da083c5a4100e929b77e750d3106a697,\n            y: 0x1f4b60f34ef91221a0b49756fa0705da93311a61af73d37a0c458877706616fb,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        0x128c0ff144fc66b6cb60eeac8a38e23da52992fc427b92397a7dffd71c45ede3,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        EmbeddedCurvePoint {\n            x: 0x015441e9d29491b06563fac16fc76abf7a9534c715421d0de85d20dbe2965939,\n            y: 0x1d2575b0276f4e9087e6e07c2cb75aa1baafad127af4be5918ef8a2ef2fea8fc,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        0x2f960e117482044dfc99d12fece2ef6862fba9242be4846c7c9a3e854325a55c,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        EmbeddedCurvePoint {\n            x: 0x1657737676968887fceb6dd516382ea13b3a2c557f509811cd86d5d1199bc443,\n            y: 0x1f39f0cb569040105fa1e2f156521e8b8e08261e635a2b210bdc94e8d6d65f77,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        0x0c96db0790602dcb166cc4699e2d306c479a76926b81c2cb2aaa92d249ec7be7,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        EmbeddedCurvePoint {\n            x: 0x0a3ceae42d14914a432aa60ec7fded4af7dad7dd4acdbf2908452675ec67e06d,\n            y: 0xfc19761eaaf621ad4aec9a8b2e84a4eceffdba78f60f8b9391b0bd9345a2f2,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        0x2cd37505871bc460a62ea1e63c7fe51149df5d0801302cf1cbc48beb8dff7e94,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        EmbeddedCurvePoint {\n            x: 0x2fb3f8b3d41ddde007c8c3c62550f9a9380ee546fcc639ffbb3fd30c8d8de30c,\n            y: 0x300783be23c446b11a4c0fabf6c91af148937cea15fcf5fb054abf7f752ee245,\n            is_infinite: false,\n        },\n    );\n}\n",
      "path": "std/hash/mod.nr"
    },
    "51": {
      "source": "// Age Verification Circuit\n// Proves that a person is at least `min_age` years old without revealing their birth year\n//\n// Public inputs:\n//   - current_year: The current year (e.g., 2025)\n//   - min_age: The minimum age threshold (e.g., 18, 21, 25)\n//   - nonce: Challenge nonce for replay resistance\n//   - claim_hash: Poseidon2(birth_year, document_hash) binding to OCR claim\n//\n// Private inputs:\n//   - birth_year: The person's birth year (kept private)\n//   - document_hash: Commitment to the document (kept private)\n//\n// Output:\n//   - Returns true if age >= min_age\n\nuse nodash::poseidon2;\n\nfn main(\n    birth_year: Field,        // Private: actual birth year\n    document_hash: Field,     // Private: document commitment\n    current_year: pub Field,  // Public: current year for verification\n    min_age: pub Field,       // Public: minimum age threshold\n    nonce: pub Field,         // Public: challenge nonce (replay resistance)\n    claim_hash: pub Field     // Public: claim hash binding to OCR data\n) -> pub bool {\n    // Nonce is included as public input for replay resistance\n    // It doesn't affect the age calculation, but binds the proof to a specific challenge\n    let _ = nonce;\n\n    // Bind proof to signed OCR claim\n    let computed_hash = poseidon2([birth_year, document_hash]);\n    assert(computed_hash == claim_hash, \"Claim hash mismatch\");\n    // Convert to u32 for safe comparison and arithmetic\n    let birth_year_u32 = birth_year as u32;\n    let current_year_u32 = current_year as u32;\n    let min_age_u32 = min_age as u32;\n\n    // SECURITY: Prevent wrap-around attack\n    // Without this check, a birth_year > current_year would cause Field underflow,\n    // resulting in a very large positive \"age\" that passes any min_age check.\n    assert(birth_year_u32 <= current_year_u32, \"Birth year cannot be in the future\");\n\n    // Calculate age safely in u32 (no overflow possible after assertion)\n    let age = current_year_u32 - birth_year_u32;\n\n    // Verify age meets minimum requirement\n    age >= min_age_u32\n}\n\n#[test]\nfn test_age_verification_adult() {\n    // Person born in 1990, current year 2025, minimum age 18\n    // Age = 2025 - 1990 = 35, which is >= 18\n    let doc_hash = 999;\n    let claim_hash = poseidon2([1990, doc_hash]);\n    let result = main(1990, doc_hash, 2025, 18, 12345, claim_hash); // nonce can be any value\n    assert(result == true);\n}\n\n#[test]\nfn test_age_verification_exactly_18() {\n    // Person born in 2007, current year 2025, minimum age 18\n    // Age = 2025 - 2007 = 18, which is >= 18\n    let doc_hash = 888;\n    let claim_hash = poseidon2([2007, doc_hash]);\n    let result = main(2007, doc_hash, 2025, 18, 99999, claim_hash);\n    assert(result == true);\n}\n\n#[test]\nfn test_age_verification_under_21() {\n    // Person born in 2007, current year 2025, minimum age 21\n    // Age = 2025 - 2007 = 18, which is < 21\n    let doc_hash = 777;\n    let claim_hash = poseidon2([2007, doc_hash]);\n    let result = main(2007, doc_hash, 2025, 21, 11111, claim_hash);\n    assert(result == false);\n}\n\n#[test]\nfn test_age_verification_minor() {\n    // Person born in 2010, current year 2025, minimum age 18\n    // Age = 2025 - 2010 = 15, which is < 18\n    let doc_hash = 666;\n    let claim_hash = poseidon2([2010, doc_hash]);\n    let result = main(2010, doc_hash, 2025, 18, 22222, claim_hash);\n    assert(result == false);\n}\n\n#[test]\nfn test_same_year_birth() {\n    // Born this year - age 0\n    let doc_hash = 555;\n    let claim_hash = poseidon2([2025, doc_hash]);\n    let result = main(2025, doc_hash, 2025, 0, 33333, claim_hash);\n    assert(result == true);\n\n    let result2 = main(2025, doc_hash, 2025, 1, 44444, claim_hash);\n    assert(result2 == false);\n}\n\n#[test(should_fail_with = \"Birth year cannot be in the future\")]\nfn test_future_birth_year_fails() {\n    // Person \"born\" in the future - should fail assertion\n    let doc_hash = 444;\n    let claim_hash = poseidon2([2030, doc_hash]);\n    let _ = main(2030, doc_hash, 2025, 18, 55555, claim_hash);\n}\n",
      "path": "/Users/gustavovalverde/dev/personal/zentity/apps/web/noir-circuits/age_verification/src/main.nr"
    },
    "54": {
      "source": "pub fn poseidon2<let N: u32>(input: impl ArrayOrBoundedVec<Field, N>) -> Field {\n    let input = input.as_bounded_vec();\n    poseidon::poseidon2::Poseidon2::hash(input.storage(), input.len())\n}\n\n// TODO: is it possible for pedersen to accept BoundedVec?\npub fn pedersen<let N: u32>(input: [Field; N]) -> Field {\n    std::hash::pedersen_hash(input)\n}\n\npub fn sha256<let N: u32>(input: impl ArrayOrBoundedVec<u8, N>) -> [u8; 32] {\n    let input = input.as_bounded_vec();\n    dep::sha256::sha256_var(input.storage(), input.len() as u64)\n}\n\npub fn partial_sha256_interstitial<let N: u32>(\n    mut h: [u32; 8],\n    input: impl ArrayOrBoundedVec<u8, N>,\n) -> [u32; 8] {\n    let input = input.as_bounded_vec();\n    dep::sha256::partial_sha256_var_interstitial(h, input.storage(), input.len())\n}\n\npub fn partial_sha256_end<let N: u32>(\n    mut h: [u32; 8],\n    partial_input: impl ArrayOrBoundedVec<u8, N>,\n    full_input_len: u32,\n) -> [u8; 32] {\n    let partial_input = partial_input.as_bounded_vec();\n    dep::sha256::partial_sha256_var_end(\n        h,\n        partial_input.storage(),\n        partial_input.len(),\n        full_input_len,\n    )\n}\n\npub fn keccak256<let N: u32>(input: impl ArrayOrBoundedVec<u8, N>) -> [u8; 32] {\n    let input = input.as_bounded_vec();\n    dep::keccak256::keccak256(input.storage(), input.len())\n}\n\n/// Needed because of https://github.com/noir-lang/noir/issues/7054\ntrait ArrayOrBoundedVec<T, let N: u32> {\n    fn as_bounded_vec(self) -> BoundedVec<T, N>;\n}\n\nimpl<T, let N: u32> ArrayOrBoundedVec<T, N> for [T; N] {\n    fn as_bounded_vec(self) -> BoundedVec<T, N> {\n        BoundedVec::from(self)\n    }\n}\n\nimpl<T, let N: u32> ArrayOrBoundedVec<T, N> for BoundedVec<T, N> {\n    fn as_bounded_vec(self) -> BoundedVec<T, N> {\n        self\n    }\n}\n\nmod tests {\n    use crate::hash::{keccak256, pedersen, poseidon2, sha256};\n\n    global FIELD_INPUT_ARR: [Field; 2] = [1, 2];\n    global FIELD_INPUT_VEC: BoundedVec<Field, 2> = BoundedVec::from(FIELD_INPUT_ARR);\n    global FIELD_INPUT_VEC_LONGER: BoundedVec<Field, 3> = BoundedVec::from(FIELD_INPUT_ARR);\n\n    global U8_INPUT_ARR: [u8; 2] = [1, 2];\n    global U8_INPUT_VEC: BoundedVec<u8, 2> = BoundedVec::from(U8_INPUT_ARR);\n    global U8_INPUT_VEC_LONGER: BoundedVec<u8, 3> = BoundedVec::from(U8_INPUT_ARR);\n\n    #[test]\n    fn test_equivalence() {\n        assert(\n            (poseidon2(FIELD_INPUT_ARR) == poseidon2(FIELD_INPUT_VEC)),\n            // TODO: is this a bug? https://discord.com/channels/1113924620781883405/1333383938198212659\n            // & (poseidon2(FIELD_INPUT_ARR) == poseidon2(FIELD_INPUT_VEC_LONGER)),\n        );\n        assert(\n            (sha256(U8_INPUT_VEC) == sha256(U8_INPUT_ARR))\n                & (sha256(U8_INPUT_VEC_LONGER) == sha256(U8_INPUT_ARR)),\n        );\n        assert(\n            (keccak256(U8_INPUT_VEC) == keccak256(U8_INPUT_ARR))\n                & (keccak256(U8_INPUT_VEC_LONGER) == keccak256(U8_INPUT_ARR)),\n        );\n    }\n\n    #[test]\n    fn test_against_std() {\n        assert(\n            poseidon2(FIELD_INPUT_ARR)\n                == poseidon::poseidon2::Poseidon2::hash(FIELD_INPUT_ARR, FIELD_INPUT_ARR.len()),\n        );\n        assert(\n            poseidon2(FIELD_INPUT_VEC_LONGER)\n                == poseidon::poseidon2::Poseidon2::hash(\n                    FIELD_INPUT_VEC_LONGER.storage(),\n                    FIELD_INPUT_VEC_LONGER.len(),\n                ),\n        );\n        assert(pedersen(FIELD_INPUT_ARR) == std::hash::pedersen_hash(FIELD_INPUT_ARR));\n        assert(\n            sha256(U8_INPUT_ARR)\n                == dep::sha256::sha256_var(U8_INPUT_ARR, U8_INPUT_ARR.len() as u64),\n        );\n        assert(\n            keccak256(U8_INPUT_ARR) == dep::keccak256::keccak256(U8_INPUT_ARR, U8_INPUT_ARR.len()),\n        );\n    }\n}\n",
      "path": "/Users/gustavovalverde/nargo/github.com/olehmisar/nodash/v0.42.0/src/hash.nr"
    },
    "72": {
      "source": "use std::default::Default;\nuse std::hash::Hasher;\n\ncomptime global RATE: u32 = 3;\n\npub struct Poseidon2 {\n    cache: [Field; 3],\n    state: [Field; 4],\n    cache_size: u32,\n    squeeze_mode: bool, // 0 => absorb, 1 => squeeze\n}\n\nimpl Poseidon2 {\n    #[no_predicates]\n    pub fn hash<let N: u32>(input: [Field; N], message_size: u32) -> Field {\n        Poseidon2::hash_internal(input, message_size, message_size != N)\n    }\n\n    pub(crate) fn new(iv: Field) -> Poseidon2 {\n        let mut result =\n            Poseidon2 { cache: [0; 3], state: [0; 4], cache_size: 0, squeeze_mode: false };\n        result.state[RATE] = iv;\n        result\n    }\n\n    fn perform_duplex(&mut self) {\n        // add the cache into sponge state\n        for i in 0..RATE {\n            // We effectively zero-pad the cache by only adding to the state\n            // cache that is less than the specified `cache_size`\n            if i < self.cache_size {\n                self.state[i] += self.cache[i];\n            }\n        }\n        self.state = crate::poseidon2_permutation(self.state, 4);\n    }\n\n    fn absorb(&mut self, input: Field) {\n        assert(!self.squeeze_mode);\n        if self.cache_size == RATE {\n            // If we're absorbing, and the cache is full, apply the sponge permutation to compress the cache\n            self.perform_duplex();\n            self.cache[0] = input;\n            self.cache_size = 1;\n        } else {\n            // If we're absorbing, and the cache is not full, add the input into the cache\n            self.cache[self.cache_size] = input;\n            self.cache_size += 1;\n        }\n    }\n\n    fn squeeze(&mut self) -> Field {\n        assert(!self.squeeze_mode);\n        // If we're in absorb mode, apply sponge permutation to compress the cache.\n        self.perform_duplex();\n        self.squeeze_mode = true;\n\n        // Pop one item off the top of the permutation and return it.\n        self.state[0]\n    }\n\n    fn hash_internal<let N: u32>(\n        input: [Field; N],\n        in_len: u32,\n        is_variable_length: bool,\n    ) -> Field {\n        let two_pow_64 = 18446744073709551616;\n        let iv: Field = (in_len as Field) * two_pow_64;\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..input.len() {\n            if i < in_len {\n                sponge.absorb(input[i]);\n            }\n        }\n\n        // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n        // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n        // fixed-length and variable-length hashes do not collide)\n        if is_variable_length {\n            sponge.absorb(1);\n        }\n        sponge.squeeze()\n    }\n}\n\npub struct Poseidon2Hasher {\n    _state: [Field],\n}\n\nimpl Hasher for Poseidon2Hasher {\n    fn finish(self) -> Field {\n        let iv: Field = (self._state.len() as Field) * 18446744073709551616; // iv = (self._state.len() << 64)\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..self._state.len() {\n            sponge.absorb(self._state[i]);\n        }\n        sponge.squeeze()\n    }\n\n    fn write(&mut self, input: Field) {\n        self._state = self._state.push_back(input);\n    }\n}\n\nimpl Default for Poseidon2Hasher {\n    fn default() -> Self {\n        Poseidon2Hasher { _state: &[] }\n    }\n}\n",
      "path": "/Users/gustavovalverde/nargo/github.com/noir-lang/poseidon/v0.1.1/src/poseidon2.nr"
    }
  },
  "expression_width": { "Bounded": { "width": 4 } }
}
